---
permalink: /
title: "Biography"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am Wenyong Zhou (周文涌), and I earned my PhD from The University of Hong Kong (HKU), where I had the privilege of being guided by the inspiring mentorship of Prof. Ngai Wong and Prof. Can Li as a proud member of the vibrant Next Gen AI (NGai) Lab family. My academic journey began with a Bachelor’s degree in 2019 from the School of Microelectronics at Tianjin University, where I was fortunate to work under the guidance of Prof. Yugong Wu, whose support sparked my curiosity for research. I later pursued my Master’s degree in Electrical and Computer Engineering at the McCormick School of Engineering, Northwestern University, where I was deeply influenced by the visionary mentorship of Prof. Seda Ogrenci.

My research focuses on implicit neural representations (INRs), exploring their potential for efficient data representation and processing. I am also working on developing next-generation computing platforms, with a particular focus on compute-in-memory (CIM) technologies to enhance efficiency. Additionally, I am passionate about optimizing Large Language Models (LLMs) through techniques such as quantization, pruning, and knowledge distillation to improve their performance and scalability.

Currently, I am working at Zhicun (Witmem) Technology, starting from November 2024, focusing on low-bit training of LLMs using cutting-edge analog compute-in-memory (CIM) technology. This research aims to unlock the potential of low-bit training, enabling more energy-efficient, faster, and scalable LLM deployment on advanced hardware.


Research Interests
======
- INRs
  - INR are a novel approach for encoding data, such as images, signals, and 3D scenes, in a continuous and compact form using neural networks.
  - My research focuses on improving the memory efficiency and generalization capabilities of these representations.
  - I am working on techniques to accelerate their training and inference for real-world deployment.

- Next-Generation Computing Platforms
  - Next-generation computing platforms aim to overcome the limitations of traditional hardware architectures, and analog CIM technology is at the forefront of this innovation.
  - My research involves designing and optimizing CIM hardware to accelerate AI computations while improving energy efficiency. 
  - I also address challenges related to device reliability, precision, and scalability, ensuring these platforms are practical for real-world applications.

- Efficient LLMs
  - Optimizing LLMs for efficiency without sacrificing performance is critical as these models grow in size.
  - My research focuses on developing advanced techniques such as quantization, pruning, and knowledge distillation to reduce the size and computational requirements of LLMs.
  - I aim to enable their deployment on resource-constrained devices while maintaining high accuracy and exploring methods to make their training and inference more energy-efficient and scalable.

Recent News
======
- 2025.08 - One paper was accepted by ASICON.
- 2025.06 - One paper was accepted by IEEE TCAS-II.
- 2025.03 - One paper was accepted by ICME 2025.
- 2025.01 - One paper was accepted by EDTM 2025.
- 2024.12 - Two papers were accepted by ICCASP 2025.
- 2024.11 - One paper was accepted by DATE 2025.

Selected Publications 
======
*: Equal contribution.
- INRs
  - **W. Zhou**, Y. Ren, Z. Liu and N. Wong. Binary Weight Multi-Bit Activation Quantization for Compute-in-Memory CNN Accelerators, *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,* (**CCF-A**).

- **W. Zhou\***, B. Li\*, T. Wu, C. Ding, Z. Liu and N. Wong. QuadINR: Quadratic Implicit Neural Representations for Efficient Memristor-based CIM System, *IEEE Transactions on Circuits and Systems II: Express Briefs*, (under review).

- **W. Zhou\***, X. Feng\*, T. Wu, M. Li, Z. Liu and N. Wong. FSM-Driven Stochastic Computing for Efficient Multi-Resolution Implicit Neural Representation, *IEEE Transactions on Circuits and Systems II: Express Briefs*, (under review).

- J. Ren\*, **W. Zhou\***, T. Wu, Y. Cheng, Z. Liu and N. Wong. Patch-Based Implicit Neural Representations for Efficient and Scalable Inference, *IEEE Transactions on Circuits and Systems II: Express Briefs*, (under review).

- X. Feng\*, **W. Zhou\***, T. Wu, M. Li, Z. Liu and N. Wong. Activation-free Implicit Neural Representation via Finite-State-Machine based Stochastic Computing, *IEEE Transactions on Circuits and Systems II: Express Briefs*, (under review).

- Y. Ren\*, **W. Zhou\***, Z. Liu and N. Wong. FreqShield: A Frequency-Domain Noise Modulation Architecture for Robust Memristor-based CNN, *IEEE Transactions on Circuits and Systems for Artificial Intelligence*, (under review).

- **W. Zhou**, T. Wu, C. Ding, Y. Ren, Z. Liu and N. Wong. Critical Weight Condensation for Robust Diffusion Models on Memristor-based CIM System, *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems*, (under review).

- T. Wu\*, C. Ding\*, **W. Zhou\***, Y. Cheng, X. Feng, C. Shi, Z. Liu and N. Wong. HaLoRA: Hardware-aware Low-Rank Adaptation for Large Language Models Based on Hybrid Compute-in-Memory Architecture, *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems*, (under review).

- **W. Zhou\***, W. Qi\*, T. Wu, Y. Cheng, Z. Liu and N. Wong. STAR: Space-Time Adaptive Resolution Downsampling for Efficient Training of Pixel-based Neural Video Representation, *ACM Multimedia 2025, Dublin, Ireland* (**CCF-A**).

- **W. Zhou\***, W. Qi\*, T. Wu, Y. Cheng, Z. Liu and N. Wong. Efficient Training of Implicit Neural Representations via Progressive Resolution and Frequency-aware Sampling, *the 34th International Joint Conference on Artificial Intelligence (IJCAI'25),* (**CCF-A**).

- **W. Zhou\***, J. Ren\*, T. Wu, Y. Cheng, Z. Liu and N. Wong. Distribution-Aware Hadamard Quantization for Hardware-Efficient Implicit Neural Representations, *2025 IEEE International Conference on Multimedia and Expo (ICME), Nantes, France, 2025,* (**CCF-B**).

- **W. Zhou\***, W. Qi\*, T. Wu, Y. Cheng, Z. Liu and N. Wong. Low-Rank Regularization for Robust Implicit Neural Representations with In-Memory Computing, *2025 IEEE International Conference on Multimedia and Expo (ICME), Nantes, France, 2025,* (**CCF-B**).

- **W. Zhou**, T. Wu, C. Ding, Y. Ren, Z. Liu and N. Wong. Towards RRAM-based Transformer-based Vision Models with Noise-aware Knowledge Distillation, *2025 Design, Automation & Test in Europe Conference & Exhibition (DATE), Lyon, France, 2025,* (**CCF-B**).

- **W. Zhou\***, T. Wu\*, Y. Cheng, C. Zhang, Z. Liu and N. Wong. MINR: Efficient Implicit Neural Representations for Multi-Image Encoding, *ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Hyderabad, India, 2025,* (**CCF-B**).

- **W. Zhou\***, Y. Cheng\*, T. Wu, C. Zhang, Z. Liu and N. Wong. Enhancing Robustness of Implicit Neural Representations Against Weight Perturbations, *ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Hyderabad, India, 2025,* (**CCF-B**).

- W. Qi\*, **W. Zhou\***, N. Wong and S.C. Chan, Hybrid Module with Multiple Receptive Fields and Self-Attention Layers for Medical Image Segmentation, *ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Seoul, Korea, Republic of, 2024,* (**CCF-B**).

- **W. Zhou\***, Y. Ren\*, J. Zhou, C. Ding, Z. Liu, and N. Wong, RRAM-Based Isotropic CNNs with High Robustness and Resource Utilization Rate, *2025 9th IEEE Electron Devices Technology & Manufacturing Conference (EDTM), Hong Kong, China, 2025*.

- **W. Zhou\***, Y. Ren\*, J. Zhou, T. Hou, and N. Wong, A Time- and Energy-Efficient CNN with Dense Connections on Memristor-Based Chips, *2023 IEEE 15th International Conference on ASIC (ASICON), Nanjing, China, 2023*.

- Z. Guan\*, **W. Zhou\***, Y. Ren, R. Xie, H. Yu and N. Wong, A Hardware-Aware Neural Architecture Search Pareto Front Exploration for In-Memory Computing, *2022 IEEE 16th International Conference on Solid-State & Integrated Circuit Technology (ICSICT), Nangjing, China, 2022*.

- Next-Generation Computing Platforms
  - Next-generation computing platforms aim to overcome the limitations of traditional hardware architectures, and analog CIM technology is at the forefront of this innovation.
  - My research involves designing and optimizing CIM hardware to accelerate AI computations while improving energy efficiency. 
  - I also address challenges related to device reliability, precision, and scalability, ensuring these platforms are practical for real-world applications.

- Efficient LLMs
  - Optimizing LLMs for efficiency without sacrificing performance is critical as these models grow in size.
  - My research focuses on developing advanced techniques such as quantization, pruning, and knowledge distillation to reduce the size and computational requirements of LLMs.
  - I aim to enable their deployment on resource-constrained devices while maintaining high accuracy and exploring methods to make their training and inference more energy-efficient and scalable.

More about me
------
- I enjoy staying active and challenging myself through sports like table tennis, badminton, and basketball. These activities not only keep me physically fit but also teach me the value of teamwork, strategy, and perseverance.
- I am deeply passionate about reading, particularly delving into history and politics through a financial lens. I find it fascinating to uncover how financial systems and economic decisions have shaped societies and historical events.
- Traveling is one of my greatest joys. It allows me to explore new cultures, meet diverse people, and experience the world from different perspectives. Each trip enriches my understanding of humanity and inspires new ways of thinking.

(Last updated on Aug., 2025)
